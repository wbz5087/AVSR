{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D,Conv3D,Conv1D\n",
    "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D,MaxPooling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM,Input,GlobalAveragePooling1D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import helpers\n",
    "from Audio import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio(path='audio/save/')\n",
    "trainlist=audio.generate_audio_list(p='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valX,valY = audio.load_audio(p='val')\n",
    "vallist = audio.generate_audio_list(p='val')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#evaluation for each class\n",
    "labels=os.listdir('audio/save/')\n",
    "model=load_model('audio_weights/first-improvement-11-0.82.hdf5')\n",
    "pred={}\n",
    "for i,label in enumerate(labels):\n",
    "    data,classes = audio.load_audio(label,'test')\n",
    "    result=model.predict(data)\n",
    "    result=np.argmax(result,axis=1)\n",
    "    classes=np.argmax(classes.toarray(),axis=1)\n",
    "    #print(classes==result)\n",
    "    acc=float(sum(result==classes))/float(len(classes))\n",
    "    #print(type(acc),type(label))\n",
    "    pred[label]=acc\n",
    "    \n",
    "sorted(pred.items(), key=lambda d:d[1], reverse = True) \n",
    "sorted(pred.items(), key=lambda d:d[1], reverse = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oscar/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "class_num = 500\n",
    "input_audio = Input(shape = (26,121))\n",
    "\n",
    "conv1d_1 = Conv1D(64,kernel_size = 3,strides=1, padding = 'same',\n",
    "               activation = 'relu')(input_audio)\n",
    "\n",
    "batch_norm1 = BatchNormalization()(conv1d_1)\n",
    "\n",
    "batch_norm1 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm1)\n",
    "\n",
    "conv1d_2 = Conv1D(128,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm1)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm2)\n",
    "\n",
    "conv1d_2 = Conv1D(512,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm2)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm2)\n",
    "\n",
    "bilstm1 = Bidirectional(LSTM(256,return_sequences=True,name='bilstm1'))(batch_norm2)\n",
    "#bilstm2 = Bidirectional(LSTM(256,return_sequences=True),name = 'bilstm2')(bilstm1)\n",
    "\n",
    "avgpool = GlobalAveragePooling1D(name='audio_avg')(bilstm1)\n",
    "\n",
    "dense1 = Dense(512,activation='relu')(avgpool)\n",
    "batch_norm3 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(class_num,activation = 'softmax')(batch_norm3)\n",
    "#maxpooling1d = MaxPooling1D(pool_size=2, padding='same')(batch_norm2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 26, 121)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 26, 64)            23296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 13, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 7, 512)            197120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 4, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "audio_avg (GlobalAveragePool (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               256500    \n",
      "=================================================================\n",
      "Total params: 2,344,052\n",
      "Trainable params: 2,341,620\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_audio], \n",
    "              outputs=[dense2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_audio.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.003, decay=1e-6, momentum=0.9)\n",
    "#adam = Adam(lr = 0.003,decay=1e-6)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "#print(sample_number)\n",
    "filepath=\"audio_weights/second-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,\n",
    "mode='max')\n",
    "stopper = EarlyStopping(monitor='val_acc',patience=3)\n",
    "callbacks_list = [checkpoint,stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 14560s 2s/step - loss: 1.8987 - acc: 0.5719 - val_loss: 1.0725 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71955, saving model to audio_weights/second-improvement-01-0.72.hdf5\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 13416s 2s/step - loss: 0.7867 - acc: 0.7896 - val_loss: 0.8226 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71955 to 0.77833, saving model to audio_weights/second-improvement-02-0.78.hdf5\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 13546s 2s/step - loss: 0.5523 - acc: 0.8495 - val_loss: 0.7443 - val_acc: 0.7986\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77833 to 0.79856, saving model to audio_weights/second-improvement-03-0.80.hdf5\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 13583s 2s/step - loss: 0.4110 - acc: 0.8886 - val_loss: 0.7120 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.79856 to 0.80877, saving model to audio_weights/second-improvement-04-0.81.hdf5\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 13309s 2s/step - loss: 0.3072 - acc: 0.9191 - val_loss: 0.7089 - val_acc: 0.8135\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80877 to 0.81350, saving model to audio_weights/second-improvement-05-0.81.hdf5\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 13494s 2s/step - loss: 0.2234 - acc: 0.9450 - val_loss: 0.7212 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.81350\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 12447s 2s/step - loss: 0.1552 - acc: 0.9669 - val_loss: 0.7371 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.81350\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 13645s 2s/step - loss: 0.1016 - acc: 0.9837 - val_loss: 0.7472 - val_acc: 0.8154\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.81350 to 0.81542, saving model to audio_weights/second-improvement-08-0.82.hdf5\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 12393s 2s/step - loss: 0.0633 - acc: 0.9938 - val_loss: 0.7524 - val_acc: 0.8208\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.81542 to 0.82083, saving model to audio_weights/second-improvement-09-0.82.hdf5\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 12541s 2s/step - loss: 0.0388 - acc: 0.9985 - val_loss: 0.7517 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.82083 to 0.82624, saving model to audio_weights/second-improvement-10-0.83.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd951b914d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_number = len(trainlist)\n",
    "val_number = len(vallist)\n",
    "batch = 64\n",
    "history=model.fit_generator(audio.generate_arrays_from_file(filelist=trainlist),\n",
    "                        validation_data=\n",
    "                    audio.generate_arrays_from_file(filelist=vallist),\n",
    "                        steps_per_epoch=sample_number // batch,\n",
    "                        validation_steps = val_number//batch,\n",
    "                        epochs=10, verbose=1,\n",
    "                   callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.savefig('audioauc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.savefig('audioloss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.793620569889362, 0.8155448717948718]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_weights('weights-improvement-04-0.98.hdf5')\n",
    "#model=load_model('audio_weights/first-improvement-10-0.82.hdf5')\n",
    "model.evaluate_generator(audio.generate_arrays_from_file(testlist,batch_size=64),\n",
    "                         steps=len(testlist)//64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
